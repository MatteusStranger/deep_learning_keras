# -*- coding: utf-8 -*-
"""deep_learning_keras.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/105cPIZewDKKxHrzulanM2bxCxsT0p0Nt
"""

import tensorflow
from tensorflow import keras
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.models import load_model

#carregar dataset
dataset = keras.datasets.fashion_mnist
((imagens_treino, identificacoes_treino),(imagens_teste, identificacoes_teste)) = dataset.load_data()

#explorar os dados
len(imagens_treino)
imagens_teste.shape
identificacoes_treino.min()
identificacoes_treino.max()

#exibir os dados
total_de_classificacoes = 10
nomes_de_classificacoes = ['Camiseta','Calça','Pullover','Vestido','Casaco','Sandália','Camisa','Tênis','Bolsa','Bota']

'''plt.imshow(imagens_treino[0])
plt.title(identificacoes_treino[0])


for imagem in range(10):
  plt.subplot(2,5,imagem+1)
  plt.imshow(imagens_treino[imagem])
  plt.title(nomes_de_classificacoes[identificacoes_treino[imagem]])
'''
plt.imshow(imagens_treino[0])
plt.colorbar()

#normalização
imagens_treino = imagens_treino/255.0

#geração de modelo
modelo = keras.Sequential([
                           keras.layers.Flatten(input_shape=(28,28)),
                           keras.layers.Dense(256,activation=tensorflow.nn.relu),
                           keras.layers.Dropout(0.4),
                           keras.layers.Dense(10,activation=tensorflow.nn.softmax)
])

modelo.compile(optimizer='adam',
               loss=tensorflow.keras.losses.sparse_categorical_crossentropy,
               metrics=['accuracy',
                        'sparse_categorical_crossentropy'])

historico = modelo.fit(imagens_treino,
           identificacoes_treino,
           batch_size=32,
           epochs=10,
           validation_split=0.2,
           callbacks=[tensorflow.keras.callbacks.EarlyStopping(monitor='loss',patience=5)])

testes = modelo.predict(imagens_teste)

perda_teste, acuracia_teste, a = modelo.evaluate(imagens_teste,identificacoes_teste,batch_size=32,verbose=1,use_multiprocessing=True)

print('Perda: ',perda_teste)
print('Acurácia: ',acuracia_teste)

plt.plot(historico.history['accuracy'])
plt.plot(historico.history['val_accuracy'])
plt.title('Acurácia por epochs')
plt.xlabel('epochs')
plt.ylabel('Accuracy')
plt.legend(['treino','avaliação'])

plt.plot(historico.history['loss'])
plt.plot(historico.history['val_loss'])
plt.title('Perda por epochs')
plt.xlabel('epochs')
plt.ylabel('Loss')
plt.legend(['loss','val_loss'])

modelo.save('modelo.h5')
modelo_salvo = load_model('modelo.h5')

perda_teste, acuracia_teste, a = modelo_salvo.evaluate(imagens_teste,identificacoes_teste,batch_size=32,verbose=1,use_multiprocessing=True)

print('Perda: ',perda_teste)
print('Acurácia: ',acuracia_teste)

